# -*- coding: utf-8 -*-
"""Shap_values.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wNKLuyxJkl9RWWnO0191VUpqZ7JQfIsw

# Shap Values

SHAP Values (an acronym from SHapley Additive exPlanations) break down a prediction to show the impact of each feature.

SHAP values interpret the impact of having a certain value for a given feature in comparison to the prediction we'd make if that feature took some baseline value.

sum(SHAP values for all features) = pred_for_team - pred_for_baseline_values

That is, the SHAP values of all features sum up to explain why my prediction was different from the baseline. This allows us to decompose a prediction in a graph like this:

sum(shap values for all features) = pred_for_team - pred_for_baseline_values

If you subtract the length of the blue bars from the length of the pink bars, it equals the distance from the base value to the output.
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

data=pd.read_csv('FIFA 2018 Statistics.csv')

y = (data['Man of the Match'] == 'Yes')
feature_names = [i for i in data.columns if data[i].dtype in [np.int64]]
x = data[feature_names]

train_x, val_x, train_y,val_y = train_test_split(x,y,random_state=1)
my_model = RandomForestClassifier(random_state=0).fit(train_x, train_y)

"""# We will look at SHAP values for a single row of the dataset"""

row_to_show = 5
data_for_prediction = val_x.iloc[row_to_show]
data_for_prediction_array = data_for_prediction.values.reshape(1,-1)
my_model.predict_proba(data_for_prediction_array)

"""The team is 70% likely to have a player win the award."""

pip install shap

import shap

# create object that can calculate shap values

explainer = shap.TreeExplainer(my_model)

# calculate shap values

shap_values = explainer.shap_values(data_for_prediction)

"""The shap_values object above is a list with two arrays. The first array is the SHAP values for a negative outcome (don't win the award), and the second array is the list of SHAP values for the positive outcome (wins the award). We typically think about predictions in terms of the prediction of a positive outcome, so we'll pull out SHAP values for positive outcomes (pulling out shap_values[1])."""

shap.initjs()
shap.force_plot(explainer.expected_value[1],shap_values[1], data_for_prediction)

